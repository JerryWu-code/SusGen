{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./pdfs/Wolfspeed_2022_TCFD.pdf already exsit.\n",
      "File ./pdfs/Siemens_2019_ESG.pdf already exsit.\n",
      "File ./pdfs/Siemens_2020_ESG.pdf already exsit.\n",
      "File ./pdfs/Prudential_2020_ESG.pdf already exsit.\n",
      "File ./pdfs/Novartis_2020_ESG.pdf already exsit.\n",
      "File ./pdfs/Novatek_2023_ESG.pdf already exsit.\n",
      "File ./pdfs/HSBC_2022_TCFD.pdf already exsit.\n",
      "File ./pdfs/Mizuho Financial Group_2020_TCFD.pdf already exsit.\n",
      "File ./pdfs/NatWest_2020_TCFD.pdf already exsit.\n",
      "File ./pdfs/CPP Investments_2020_ESG.pdf already exsit.\n",
      "File ./pdfs/TD Bank_2020_TCFD.pdf already exsit.\n",
      "File ./pdfs/TSMC_2022_TCFD.pdf already exsit.\n",
      "File ./pdfs/Standard Chartered_2020_TCFD.pdf already exsit.\n",
      "File ./pdfs/Nedbank_2020_TCFD.pdf already exsit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./pdfs/Wolfspeed_2022_TCFD.pdf',\n",
       " './pdfs/Siemens_2019_ESG.pdf',\n",
       " './pdfs/Siemens_2020_ESG.pdf',\n",
       " './pdfs/Prudential_2020_ESG.pdf',\n",
       " './pdfs/Novartis_2020_ESG.pdf',\n",
       " './pdfs/Novatek_2023_ESG.pdf',\n",
       " './pdfs/HSBC_2022_TCFD.pdf',\n",
       " './pdfs/Mizuho Financial Group_2020_TCFD.pdf',\n",
       " './pdfs/NatWest_2020_TCFD.pdf',\n",
       " './pdfs/CPP Investments_2020_ESG.pdf',\n",
       " './pdfs/TD Bank_2020_TCFD.pdf',\n",
       " './pdfs/TSMC_2022_TCFD.pdf',\n",
       " './pdfs/Standard Chartered_2020_TCFD.pdf',\n",
       " './pdfs/Nedbank_2020_TCFD.pdf']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Susgen2024 for nus and A star.\n",
    "Author: Xuan Wang\n",
    "2024/05/26\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"Get pdf info from json file, then copy to destinated directory from raw directory.\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def get_pdf_list(json_file_path):\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    pdf_list = [item['file'] for item in data if 'file' in item]\n",
    "    return pdf_list\n",
    "\n",
    "def copy_pdfs_to_destination(pdf_list, source_dir, destination_dir):\n",
    "    dest_files = []\n",
    "\n",
    "    if not os.path.exists(destination_dir):\n",
    "        os.makedirs(destination_dir)\n",
    "    \n",
    "    for pdf in pdf_list:\n",
    "        src_path = os.path.join(source_dir, pdf)\n",
    "        dest_path = os.path.join(destination_dir, pdf)\n",
    "        dest_files.append(dest_path)\n",
    "        if os.path.exists(dest_path):\n",
    "            print(f\"File {dest_path} already exsit.\")\n",
    "            continue\n",
    "\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.copy(src_path, dest_path)\n",
    "            print(f\"Copied {src_path} to {dest_path}\")\n",
    "        else:\n",
    "            print(f\"File {src_path} does not exist\")\n",
    "    \n",
    "    return dest_files\n",
    "\n",
    "\n",
    "json_file_path = './jsons/qa_dict.json'\n",
    "pdf_list = get_pdf_list(json_file_path)\n",
    "# print(f\"{len(pdf_list)} files: {pdf_list}\")\n",
    "\n",
    "source_dir = '../raw_data/raw_pdf/'\n",
    "destination_dir = './pdfs/'\n",
    "dest_files = copy_pdfs_to_destination(pdf_list, source_dir, destination_dir)\n",
    "dest_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import torch\n",
    "from typing import List, Union, Tuple\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from llama_index.core import Settings\n",
    "\n",
    "torch.set_default_device('cuda')\n",
    "# torch.set_default_device('cpu')\n",
    "# ERROR to show only errors, INFO to show all logs\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO) \n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "# Set the log level for the sentence_transformers package\n",
    "logging.getLogger('sentence_transformers').setLevel(logging.ERROR)\n",
    "logging.getLogger().setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llm_embed(llm_args: dict, embed_path: str) -> Tuple[HuggingFaceLLM, HuggingFaceEmbeddings]:\n",
    "    llm = HuggingFaceLLM(**llm_args)\n",
    "    embed_model = HuggingFaceEmbeddings(model_name=embed_path)\n",
    "    return llm, embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(file_paths: Union[str, List[str]]) -> List:\n",
    "    if isinstance(file_paths, str):\n",
    "        documents = SimpleDirectoryReader(input_dir=file_paths).load_data()\n",
    "    elif isinstance(file_paths, list):\n",
    "        documents = SimpleDirectoryReader(input_files=file_paths).load_data()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid input. Please provide a string or list of strings.\")\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_qa(index: VectorStoreIndex, query_str: str) -> str:\n",
    "    query_engine = index.as_query_engine()\n",
    "    response = query_engine.query(query_str)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "\"You are a Q&A assistant in financial domain. \"\n",
    "\"Your goal is to answer questions as accurately as possible \"\n",
    "\"based on the instructions and context provided.\"\n",
    ")\n",
    "# This will wrap the default prompts that are internal to llama-index\n",
    "query_wrapper_prompt = \"<|USER|>{query_str}<|ASSISTANT|>\"\n",
    "mistral_v2 = \"/home/whatx/SusGen/ckpts/Mistral-7B-Instruct-v0.2-hf\"\n",
    "llama3 = \"/home/whatx/SusGen/ckpts/Meta-Llama-3-8B-Instruct-hf\"\n",
    "llm_path = mistral_v2 # llama3\n",
    "embed_model_path = \"/home/whatx/SusGen/ckpts/all-mpnet-base-v2\"\n",
    "\n",
    "llm_args = {\n",
    "    \"system_prompt\": system_prompt,\n",
    "    \"query_wrapper_prompt\": query_wrapper_prompt,\n",
    "    \"device_map\": \"auto\",\n",
    "    \"context_window\": 5120,\n",
    "    \"max_new_tokens\": 4096,\n",
    "    \"generate_kwargs\": {\"temperature\": 0.1, \"do_sample\": True},\n",
    "    \"tokenizer_kwargs\": {\"max_length\": 4096},\n",
    "    \"model_kwargs\": {\"torch_dtype\": torch.float16},\n",
    "    \"model_name\": llm_path,\n",
    "    \"tokenizer_name\": llm_path,\n",
    "}\n",
    "\n",
    "# Load the LLM and Embedding model\n",
    "llm, embed_model = load_llm_embed(llm_args, embed_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidates documents ~ Folder path or file list: \n",
    "docu_files = [\"./pdfs/Wolfspeed_2022_TCFD.pdf\"]\n",
    "# docu_files = dest_files\n",
    "\n",
    "documents_path = docu_files\n",
    "text_chunking = 1024\n",
    "\n",
    "# Load the documents\n",
    "documents = load_documents(documents_path)\n",
    "print(f\"document: {documents}\")\n",
    "\n",
    "# Setting\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.chunk_size = text_chunking\n",
    "index = VectorStoreIndex.from_documents(documents, settings=Settings)\n",
    "\n",
    "# RAG_QA\n",
    "# query_str = \"What is the revenue of the company in 2020?\"\n",
    "query_str = \"You are an expert in tcfd report, \\\n",
    "            please read the provided PDF document and summarize the company's introduction into a single paragraph of approximately 200 words. \\\n",
    "            Ensure the summary is concise, informative, and captures the essence of the company's identity and operations.\"\n",
    "response = rag_qa(index, query_str)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG_QA\n",
    "# query_str = \"What is the revenue of the company in 2020?\"\n",
    "query_str = \"You are an expert in tcfd report, \\\n",
    "            please read the provided PDF document and summarize the company's introduction into a single paragraph of approximately 200 words. \\\n",
    "            Ensure the summary is concise, informative, and captures the essence of the company's identity and operations.\"\n",
    "response = rag_qa(index, query_str)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the txt into json in the format of {files: <***.pdf>, summary: <intro of the company>, content: <qa pair>}\n",
    "\n",
    "import json\n",
    "\n",
    "def add_summaries_to_json(json_file_path, summaries):\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    for entry in data:\n",
    "        file_name = entry.get('file')\n",
    "        if file_name in summaries:\n",
    "            entry['summary'] = summaries[file_name]\n",
    "\n",
    "    with open(json_file_path, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "    \n",
    "    print(\"Summaries added successfully.\")\n",
    "\n",
    "json_file_path = './sum_qa_dict.json'  # JSON文件路径\n",
    "\n",
    "# intro in dict\n",
    "summaries = {\n",
    "    \"Wolfspeed_2022_TCFD.pdf\": ,\n",
    "    \"Siemens_2019_ESG.pdf\": ,\n",
    "}\n",
    "\n",
    "add_summaries_to_json(json_file_path, summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_str = \"As a specialist in the TCFD framework, elaborate on how to refine an organization\\u2019s TCFD report, specifically addressing Governance, Strategy, Risk Management, and Metrics & Targets to better capture climate-related risks and opportunities.Answer the following questions: \\n1. Disclose Scope 1, Scope 2, and, if appropriate, Scope 3 greenhouse gas (GHG) emissions, and the related risks.\\n\"\n",
    "# response = rag_qa(index, query_str)\n",
    "# print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "susgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
