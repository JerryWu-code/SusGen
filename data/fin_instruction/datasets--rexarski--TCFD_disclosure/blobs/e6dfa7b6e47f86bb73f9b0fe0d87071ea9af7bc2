---
dataset_info:
  features:
  - name: question
    dtype: string
  - name: text
    dtype: string
  - name: label
    dtype: string
  splits:
  - name: train
    num_bytes: 191356
    num_examples: 593
  download_size: 58524
  dataset_size: 191356
license: mit
task_categories:
- text-classification
language:
- en
tags:
- climate
pretty_name: Sentence dataset extracted from TCFD recommendations for climate disclosure
  category classification.
size_categories:
- n<1K
---
# Dataset Card for "TCFD_disclosure"

### Dataset Summary

This dataset was created to aid our team in developing a model to address two climate-related tasks: Fact Checking, and TCFD Classification, both of which are discussed below.
These two tasks are believed to be solveable with a BERT Language model, as identified by the [ClimateBERT](https://climatebert.ai/about) team. However, conclusive benchmarks or model weights for these
tasks were never released, leading to our team developing our own approach to these problems.

### Data Fields

Our dataset contains 540 records, each of which is composed of several attributes:

- `question`: a `string` feature, provides additional detail about the particular TCFD category a particular document is labeled as. 
- `text`: a `string` feature, containes the raw text of the sentence from the document that best characterizes a particular document. 
- `label`: a `string` feature, identifies which of the 11 TCFD categories this document is labeled as.


### Source Data

The reports used as the basis of the dataset were drawn from the Task Force on Climate-Related Financial Disclosures (TCFD) list of [Example Disclosures](https://www.fsb-tcfd.org/example-disclosures/).
These documents were provided by TCFD to highlight climate-related financial disclosures that align with one or more of the TCFDâ€™s 11 recommended categories. With this in mind,
we can think of this list as exemplars for disclosures that display clear alignment and focus throughout the document. 

### Methodology

This dataset was curated by our team through a custom processing pipeline, to ensure the creation of a dataset in a way that was reproducible, explainable, and correct. A collection of
financial disclosures was highlighted by the TCFD, as discussed above. These reports served as the foundation of our dataset, giving our team a curated selection of data upon which to build our dataset.
These reports were scraped from the TCFD website via [Selenium](https://www.selenium.dev/), a tool designed to automate the collection of publicly available data from websites. With it we were able to
save the example disclosures as PDF files for processing. The collected documents already contained a label, provided by the TCFD in regards to its 11 identified categories for disclosures (discussed on page 112 of the [following report](https://assets.bbhub.io/company/sites/60/2022/10/2022-TCFD-Status-Report.pdf)).
With these labels in mind, we used a custom Python tool called [`ChitChat`](https://github.com/rexarski/chitchat) to return key sentences from each of the example disclosures. For the purposes of this study we returned five sentences from each report, giving us a total of 540 data points.
 Each of the five created sentences shares the original label of the root document they come from. More information about our processing pipeline and further analysis can be found on our project page, or by contacting any of the authors of this project.

### Languages

The text contained in the dataset is entirely in English, as found in the real-world financial disclosures identified by the TCFD. The associated BCP-47 code is [`en`](https://www.techonthenet.com/js/language_tags.php), to ensure clear labeling of language usage for downstream tasks and other future applications.

[More Information needed](https://github.com/huggingface/datasets/blob/main/CONTRIBUTING.md#how-to-contribute-to-the-dataset-cards)